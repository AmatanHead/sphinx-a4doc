import os
import dataclasses
import docutils.parsers.rst
import docutils.statemachine
import docutils.nodes
import sphinx.addnodes
import sphinx.util.docutils

from sphinx_a4doc.contrib.configurator import ManagedDirective

from sphinx_a4doc.settings import GrammarType, OrderSettings, GroupingSettings, EndClass
from sphinx_a4doc.settings import global_namespace, autodoc_namespace, diagram_namespace
from sphinx_a4doc.domain import Grammar, Rule
from sphinx_a4doc.diagram_directive import RailroadDiagramNode
from sphinx_a4doc.model.model import ModelCache, Model, RuleBase
from sphinx_a4doc.model.reachable_finder import find_reachable_rules
from sphinx_a4doc.model.model_renderer import Renderer
from sphinx_a4doc.contrib.marker_nodes import find_or_add_marker

from typing import *


class AutoGrammar(sphinx.util.docutils.SphinxDirective, ManagedDirective):
    """
    Autogrammar directive generates a grammar description by reading a ``.g4``
    file and inspecting its documentation comments.

    The :rst:dir:`a4:autogrammar` directive designed to behave like it's
    :rst:dir:`a4:grammar`

    Its only argument, ``name``, should contain name of the grammar which
    will be parsed. It is passed unchanged to a grammar resolver which,
    by default, loads a file ``{a4_base_path}/{name}.g4`` (where
    ``a4_base_path`` is a variable defined in ``conf.py``). See more on how
    to customize grammar file lookup process in the ':ref:`custom_lookup`'
    section.

    .. TODO: reference to global settings

    See more on how to write documentation comments and control look of the
    automatically generated railroad diagrams in the ':ref:`grammar_comments`'
    section.

    """

    required_arguments = 1
    has_content = True

    settings = autodoc_namespace.for_directive()

    diagram_settings = diagram_namespace.for_directive('diagram')

    def __init__(self, *args, **kwargs):
        super().__init__(*args, *kwargs)

        self.used_models: Set[Model] = set()
        self.root_rule: Optional[RuleBase] = None

    def run(self):
        # Load model from file
        model = self.load_model(self.arguments[0])
        # Early exit
        if model.has_errors():
            self.register_deps()
            return [
                self.state_machine.reporter.error(
                    'unable to document this grammar',
                    line=self.lineno
                )
            ]
        # Create the `Grammar` directive which will be used for nested parse
        grammar_dir = self.make_grammar_directive(model)
        # From now on we want diagram settings to affect every nested diagram
        self.push_settings(diagram_namespace, self.diagram_settings)
        try:
            # Create a skeleton of the grammar description
            nodes = grammar_dir.run()
            # If user described some rules manually, we want that descriptions
            # to replace ones obtained from the grammar file. We also want to
            # remove all descriptions temporarily to rearrange them according
            # to the `ordering` settings
            desc_content, rule_nodes = self.cut_rule_descriptions(model, nodes)
            # Set proper ref_context
            grammar_dir.before_content()
            try:
                # Find place where docstring should be rendered
                doc_node = find_or_add_marker(desc_content, 'docstring')
                # Render model docstring
                self.render_docs(model.get_path(), model.get_model_docs(), doc_node)
                # Insert docstring to the document
                doc_node.replace_self(doc_node.children)
                # Find place where to insert rule descriptions
                rules_node = find_or_add_marker(desc_content, 'members')
                # Arrange rules found in the grammar file and render them
                for rule in self.make_order(model):
                    # Manual description overrides autogenerated description
                    if rule.name in rule_nodes:
                        rules_node.append(rule_nodes.pop(rule.name))
                    else:
                        rules_node.extend(self.make_rule(rule))
                # Add any rule that was described manually but that wasn't found
                # in the grammar file
                for rule in sorted(rule_nodes.values(), key=lambda x: x.line):
                    rules_node.append(rule)
                # Insert rule descriptions to the document
                rules_node.replace_self(rules_node.children)
            finally:
                grammar_dir.after_content()

            return nodes
        finally:
            self.pop_settings(diagram_namespace)
            self.register_deps()

    def load_model(self, name: str) -> Model:
        # TODO: use grammar resolver
        base_path = global_namespace.load_global_settings(self.env).base_path
        path = os.path.join(base_path, name + '.g4')
        model = ModelCache.instance().from_file(path)
        self.used_models.add(model)
        return model

    def make_grammar_directive(self, model):
        options = {
            'imports': [i.get_name() for i in model.get_imports() if i.get_name()],
        }

        if 'noindex' in self.options:
            options['noindex'] = None

        if self.settings.name:
            options['name'] = self.settings.name

        if model.get_type():
            options['type'] = GrammarType[model.get_type().upper()]

        return Grammar(
            name='a4:grammar',
            arguments=[model.get_name()],
            options=options,
            content=self.content,
            lineno=self.lineno,
            content_offset=self.content_offset,
            block_text=self.block_text,
            state=self.state,
            state_machine=self.state_machine
        )

    def cut_rule_descriptions(self, model, nodes):
        desc_content = None

        rule_nodes = {}

        for node in nodes:
            if not isinstance(node, sphinx.addnodes.desc):
                continue

            for content_node in node.children:
                if isinstance(content_node, sphinx.addnodes.desc_content):
                    desc_content = content_node
                    break
            else:
                raise RuntimeError('no desc_content can be found')
            for rule_node in node.traverse(
                lambda x: (
                    isinstance(x, sphinx.addnodes.desc) and
                    x['domain'] == 'a4' and
                    x['objtype'] == 'rule'
                )
            ):
                sig = rule_node.next_node(sphinx.addnodes.desc_signature)

                if sig is None:
                    continue

                prefix = f'a4.{model.get_name()}.'

                for ident in sig['ids']:
                    if ident.startswith(prefix):
                        rule_nodes[ident[len(prefix):]] = rule_node
                        rule_node.replace_self([])
                        break

        assert desc_content is not None

        return desc_content, rule_nodes

    def make_order(self, model: Model) -> List[RuleBase]:
        lexer_rules = []
        if self.settings.lexer_rules:
            lexer_rules = model.get_terminals()
            if not self.settings.fragments:
                lexer_rules = filter(lambda r: not r.is_fragment, lexer_rules)
            if not self.settings.undocumented:
                lexer_rules = filter(lambda r: r.documentation, lexer_rules)
        lexer_rules = list(lexer_rules)

        parser_rules = []
        if self.settings.parser_rules:
            parser_rules = model.get_non_terminals()
            if not self.settings.undocumented:
                parser_rules = filter(lambda r: r.documentation, parser_rules)
        parser_rules = list(parser_rules)

        precedence = {
            OrderSettings.BY_SOURCE: lambda rule: rule.position,
            OrderSettings.BY_NAME: lambda rule: rule.name.lower(),
        }[self.settings.ordering]

        if self.settings.grouping is GroupingSettings.MIXED:
            all_rules = sorted(lexer_rules + parser_rules, key=precedence)
        elif self.settings.grouping is GroupingSettings.LEXER_FIRST:
            all_rules = sorted(lexer_rules, key=precedence) + sorted(parser_rules, key=precedence)
        elif self.settings.grouping is GroupingSettings.PARSER_FIRST:
            all_rules = sorted(parser_rules, key=precedence) + sorted(lexer_rules, key=precedence)
        else:
            raise RuntimeError('invalid grouping parameter')

        if self.settings.only_reachable_from:
            rule_name = self.settings.only_reachable_from
            rule_model = model
            if '.' in rule_name:
                model_name, rule_name = rule_name.split('.', 1)
                rule_model = self.load_model(model_name)
            rule = rule_model.lookup(rule_name)
            self.root_rule = rule
            if rule is None:
                return all_rules
            reachable = find_reachable_rules(rule)
            return [r for r in all_rules if r in reachable]

        return all_rules

    def make_rule(self, rule: RuleBase) -> List[docutils.nodes.Node]:
        if rule.is_doxygen_nodoc or rule.is_doxygen_inline:
            return []  # implicitly disabled
        if not rule.documentation and rule.content is None:
            return []  # nothing to document

        options = {}
        if 'noindex' in self.options:
            options['noindex'] = None
        if rule.display_name:
            options['name'] = rule.display_name

        rule_dir = Rule(
            name='a4:rule',
            arguments=[rule.name],
            options=options,
            content=docutils.statemachine.StringList(),
            lineno=self.lineno,
            content_offset=self.content_offset,
            block_text=self.block_text,
            state=self.state,
            state_machine=self.state_machine
        )

        nodes = rule_dir.run()

        for node in nodes:
            if not isinstance(node, sphinx.addnodes.desc):
                continue

            for content_node in node.children:
                if isinstance(content_node, sphinx.addnodes.desc_content):
                    desc_content = content_node
                    break
            else:
                raise RuntimeError('no desc_content can be found')

            if rule.documentation:
                self.render_docs(rule.position.file, rule.documentation[:1], desc_content)
                docs = rule.documentation[1:]
            else:
                docs = rule.documentation

            if not rule.is_doxygen_no_diagram:
                env = self.env
                grammar = env.ref_context.get('a4:grammar', '__default__')
                dia = Renderer().visit(rule.content)

                settings = self.diagram_settings

                if (
                    self.settings.mark_root_rule and
                    self.root_rule is not None and
                    rule.name == self.root_rule.name and
                    rule.model is self.root_rule.model
                ):
                    settings = dataclasses.replace(settings, end_class=EndClass.COMPLEX)
                desc_content.append(
                    RailroadDiagramNode(dia, settings, grammar)
                )

            self.render_docs(rule.position.file, docs, desc_content)

            break

        return nodes

    def render_docs(self, path: str, docs: List[Tuple[int, str]], node):
        docs = docs or []

        for line, doc in docs:
            lines = doc.splitlines()
            items = [(path, line + i - 1) for i in range(len(lines))]

            content = docutils.statemachine.StringList(lines, items=items)

            with sphinx.util.docutils.switch_source_input(self.state, content):
                self.state.nested_parse(content, 0, node)

    def register_deps(self):
        seen = set()
        models = self.used_models.copy()
        while models:
            model = models.pop()
            if model in seen:
                continue
            if not model.is_in_memory():
                self.state.document.settings.record_dependencies.add(model.get_path())
            models.update(model.get_imports())
            seen.add(model)
